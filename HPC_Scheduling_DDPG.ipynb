{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a6b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.spaces import Box, Discrete\n",
    "from gym.utils import seeding\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import datetime\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d331109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default Parameters for HPC\n",
    " \n",
    "max_q_size = 256\n",
    "mlp_size = 1024\n",
    "wait_max_t = 14400\n",
    "run_max_t = 14400\n",
    "task_fea = 6\n",
    "debug = False\n",
    "task_seq_t = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd70d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\IUB\\Course_Work\\Sem-II\\RL\\Project\\Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e61e3cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Machine State\n",
    "\n",
    "def start_mach(id):\n",
    "    id = id\n",
    "    run_ts_id= -1\n",
    "    free_now = True\n",
    "    past_tasks = []\n",
    "    \n",
    "def task_details(past_tasks, ts_id):\n",
    "    if free_now:\n",
    "        run_ts_id = ts_id\n",
    "        free_now = False\n",
    "        past_tasks.append(ts_id)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def reset(run_ts_id):\n",
    "    free_now = True\n",
    "    run_ts_id = -1\n",
    "    past_tasks = []\n",
    "    \n",
    "def release(free_now,run_ts_id):\n",
    "    if free_now:\n",
    "        return -1\n",
    "    else:\n",
    "        free_now = True\n",
    "        run_ts_id = -1\n",
    "        return 1\n",
    "\n",
    "def id_update(id):\n",
    "    return \"M[\"+str(id)+\"] \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfcbc81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Clusters\n",
    "\n",
    "def def_clus(cluster_name, node_num, num_procs_per_node):\n",
    "    clus_name = cluster_name\n",
    "    total_num_node = node_num\n",
    "    node_free = node_num\n",
    "    node_used = 0\n",
    "    procs_pnode = procs_pnode\n",
    "    all_nodes = []\n",
    "\n",
    "    for i in range(total_node):\n",
    "        all_nodes.append(start_mach(i))\n",
    "    return all_nodes, node_used,clus_name, total_num_node\n",
    "\n",
    "def alloc_tas(task):\n",
    "    if task.request_number_of_nodes != -1 and task.request_number_of_nodes > free_node:\n",
    "        return False\n",
    "    if task.request_number_of_nodes != -1 and task.request_number_of_nodes <= free_node:\n",
    "        return True\n",
    "\n",
    "def alloc(task_id, request_num_procs):\n",
    "    alloc_nodes = []\n",
    "    req_node = int(round(request_num_procs) / (num_procs_per_node))\n",
    "\n",
    "    if req_node >free_node:\n",
    "        return []\n",
    "\n",
    "    alloc = 0\n",
    "\n",
    "    for t in all_nodes:\n",
    "        if allocated == req_node:\n",
    "            return allocated_nodes\n",
    "        if t.taken_by_task(task_id):\n",
    "            allocated += 1\n",
    "            nd_used += 1\n",
    "            nod_free -= 1\n",
    "            alloc_nodes.append(t)\n",
    "\n",
    "    if alloc == req_node:\n",
    "        return alloc_nodes\n",
    "\n",
    "    print (\"Free nodes but cant be allocated.\")\n",
    "    return []\n",
    "\n",
    "    req_node = int(round((task.req_no_procs)/(num_procs_pnode)))\n",
    "    task.req_no_procs = req_node\n",
    "    if req_node > free_node:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def reset():\n",
    "    used_nod = 0\n",
    "    free_nod = all_node\n",
    "    for i in all_nodes:\n",
    "        i.reset()\n",
    "\n",
    "def check_free(used_node):\n",
    "    if used_node == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def free_node_action(removes, used_node, free_node):\n",
    "    used_node -= len(removes)\n",
    "    free_node += len(removes)\n",
    "\n",
    "    for t in removes:\n",
    "        t.free_node_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81469472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_shape(length, shape=None):\n",
    "    if shape is None:\n",
    "        return (length,)\n",
    "    return (length, shape) if np.isscalar(shape) else (length, *shape)\n",
    "\n",
    "def placeholder(dim=None):\n",
    "    return tf.placeholder(dtype=tf.float32, shape=combined_shape(None, dim))\n",
    "\n",
    "\n",
    "def placeholders(*args):\n",
    "    return [placeholder(dim) for dim in args]\n",
    "\n",
    "\n",
    "def placeholder_from_space(space):\n",
    "    if isinstance(space, Box):\n",
    "        return placeholder(space.shape)\n",
    "    elif isinstance(space, Discrete):\n",
    "        return tf.placeholder(dtype=tf.int32, shape=(None,))\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def placeholders_from_spaces(*args):\n",
    "    return [placeholder_from_space(space) for space in args]\n",
    "\n",
    "\n",
    "def get_vars(scope=''):\n",
    "    return [x for x in tf.trainable_variables() if scope in x.name]\n",
    "\n",
    "\n",
    "def count_vars(scope=''):\n",
    "    v = get_vars(scope)\n",
    "    return sum([np.prod(var.shape.as_list()) for var in v])\n",
    "\n",
    "\n",
    "def discount_cumsum(x, discount):\n",
    "    return scipy.signal.lfilter([1], [1, float(-discount)], x[::-1], axis=0)[::-1]\n",
    "\n",
    "def hpc_init():\n",
    "    action_space = spaces.Discrete(max_q_size)\n",
    "    observation_space = spaces.Box(low=0.0, high=1.0,shape=(task_fea * max_q_size,),dtype=np.float32)\n",
    "\n",
    "    task_q = []\n",
    "    running_tasks = []\n",
    "    vsbl_tasks = []\n",
    "    pairs = []\n",
    "\n",
    "    current_timestamp = 0\n",
    "    start = 0\n",
    "    next_arriving_task_idx = 0\n",
    "    last_task_in_batch = 0\n",
    "    num_task_in_batch = 0\n",
    "    start_idx_last_reset = 0\n",
    "\n",
    "    loads = None\n",
    "    cluster = None\n",
    "\n",
    "    bsld_algo_dict = {}\n",
    "    scheduled_rl = {}\n",
    "    penalty = 0\n",
    "    pivot_task = False\n",
    "    scheduled_scores = []\n",
    "\n",
    "    enable_preworkloads = False\n",
    "    pre_workloads = []\n",
    "\n",
    "def start_hpc( workload_file='', sched_file=''):\n",
    "    print(\"loading from dataset:\", workload_file)\n",
    "    loads = Workloads(workload_file)\n",
    "    cluster = def_clus(loads.max_nodes, loads.max_procs / loads.max_nodes)\n",
    "    penalty_task_score = task_seq_siz * loads.max_exec_time / 10\n",
    "\n",
    "def seed(seed=None):\n",
    "    np_random, seed = seeding.np_random(seed)\n",
    "    return [seed]\n",
    "\n",
    "def gen_preworkloads(size):\n",
    "\n",
    "    running_task_size = size\n",
    "    for i in range(running_task_size):\n",
    "        _task = loads[start - i - 1]\n",
    "        req_num_of_processors = _task.request_number_of_processors\n",
    "        runtime_of_task = _task.request_time\n",
    "        task_tmp = Task()\n",
    "        task_tmp.task_id = (-1 - i)\n",
    "        task_tmp.request_number_of_processors = req_num_of_processors\n",
    "        task_tmp.run_time = runtime_of_task\n",
    "        if cluster.can_allocated(task_tmp):\n",
    "            running_tasks.append(task_tmp)\n",
    "            task_tmp.scheduled_time = max(0, (current_timestamp - random.randint(0, max(runtime_of_task, 1))))\n",
    "            task_tmp.allocated_machines = cluster.allocate(task_tmp.task_id, task_tmp.request_number_of_processors)\n",
    "            pre_workloads.append(task_tmp)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "def refill_preworkloads():\n",
    "    for _task in pre_workloads:\n",
    "        running_tasks.append(_task)\n",
    "        _task.allocated_machines = cluster.allocate(_task.task_id, _task.request_number_of_processors)\n",
    "\n",
    "def reset(task_seq_siz):\n",
    "    cluster.reset()\n",
    "    loads.reset()\n",
    "\n",
    "    task_queue = []\n",
    "    running_tasks = []\n",
    "    vsbl_tasks = []\n",
    "    pairs = []\n",
    "\n",
    "    current_timestamp = 0\n",
    "    start = 0\n",
    "    next_arriving_task_idx = 0\n",
    "    last_task_in_batch = 0\n",
    "    num_task_in_batch = 0\n",
    "    scheduled_rl = {}\n",
    "    penalty = 0\n",
    "    pivot_task = False\n",
    "    scheduled_scores = []\n",
    "\n",
    "    pre_workloads = []\n",
    "\n",
    "    start = np_random.randint(task_seq_siz, (loads.size() - task_seq_siz - 1))\n",
    "    start_idx_last_reset = start\n",
    "    num_task_in_batch = task_seq_siz\n",
    "    last_task_in_batch = start + num_task_in_batch\n",
    "    current_timestamp = loads[start].submit_time\n",
    "    task_queue.append(loads[start])\n",
    "    next_arriving_task_idx = start + 1\n",
    "\n",
    "    if enable_preworkloads:\n",
    "        gen_preworkloads(task_seq_siz + np_random.randint(task_seq_siz))\n",
    "\n",
    "    return build_observation(), build_critic_obs()\n",
    "\n",
    "def reset_for_test(num, start):\n",
    "    cluster.reset()\n",
    "    loads.reset()\n",
    "\n",
    "    task_queue = []\n",
    "    running_tasks = []\n",
    "    vsbl_tasks = []\n",
    "    pairs = []\n",
    "\n",
    "    current_timestamp = 0\n",
    "    start = 0\n",
    "    next_arriving_task_idx = 0\n",
    "    last_task_in_batch = 0\n",
    "    num_task_in_batch = 0\n",
    "    scheduled_rl = {}\n",
    "    penalty = 0\n",
    "    pivot_task = False\n",
    "    scheduled_scores = []\n",
    "\n",
    "    task_seq_siz = num\n",
    "\n",
    "    start = np_random.randint(task_seq_siz, (loads.size() - task_seq_siz - 1))\n",
    "    start_idx_last_reset = start\n",
    "    num_task_in_batch = task_seq_siz\n",
    "    last_task_in_batch = start + num_task_in_batch\n",
    "    current_timestamp = loads[start].submit_time\n",
    "    task_queue.append(loads[start])\n",
    "    next_arriving_task_idx = start + 1\n",
    "\n",
    "def moveforward_for_resources_backfill_greedy(task, scheduled_logs):\n",
    "    assert not cluster.can_allocated(task)\n",
    "\n",
    "    earliest_start_time = current_timestamp\n",
    "    running_tasks.sort(key=lambda running_task: (running_task.scheduled_time + running_task.request_time))\n",
    "    free_processors = cluster.free_node * cluster.num_procs_per_node\n",
    "    for running_task in running_tasks:\n",
    "        free_processors += len(running_task.allocated_machines) * cluster.num_procs_per_node\n",
    "        earliest_start_time = (running_task.scheduled_time + running_task.request_time)\n",
    "        if free_processors >= task.request_number_of_processors:\n",
    "            break\n",
    "\n",
    "    while not cluster.can_allocated(task):\n",
    "\n",
    "        #backfill tasks\n",
    "        task_queue.sort(key=lambda _j: fcfs_score(_j))\n",
    "        task_queue_iter_copy = list(task_queue)\n",
    "        for _j in task_queue_iter_copy:\n",
    "            if cluster.can_allocated(_j) and (current_timestamp + _j.request_time) < earliest_start_time:\n",
    "                assert _j.scheduled_time == -1\n",
    "                _j.scheduled_time = current_timestamp\n",
    "                _j.allocated_machines = cluster.allocate(_j.task_id, _j.request_number_of_processors)\n",
    "                running_tasks.append(_j)\n",
    "                score = (task_score(_j) / num_task_in_batch)\n",
    "                scheduled_logs[_j.task_id] = score\n",
    "                task_queue.remove(_j)\n",
    "\n",
    "        assert running_tasks\n",
    "        running_tasks.sort(key=lambda running_task: (running_task.scheduled_time + running_task.run_time))\n",
    "        next_resource_release_time = (running_tasks[0].scheduled_time + running_tasks[0].run_time)\n",
    "        next_resource_release_machines = running_tasks[0].allocated_machines\n",
    "\n",
    "        if next_arriving_task_idx < last_task_in_batch \\\n",
    "                and loads[next_arriving_task_idx].submit_time <= next_resource_release_time:\n",
    "            current_timestamp = max(current_timestamp, loads[next_arriving_task_idx].submit_time)\n",
    "            task_queue.append(loads[next_arriving_task_idx])\n",
    "            next_arriving_task_idx += 1\n",
    "        else:\n",
    "            current_timestamp = max(current_timestamp, next_resource_release_time)\n",
    "            cluster.release(next_resource_release_machines)\n",
    "            running_tasks.pop(0)\n",
    "\n",
    "def schedule_curr_sequence_reset(score_fn):\n",
    "    scheduled_logs = {}\n",
    "    while True:\n",
    "        task_queue.sort(key=lambda j: score_fn(j))\n",
    "        task_for_scheduling = task_queue[0]\n",
    "        if not cluster.can_allocated(task_for_scheduling):\n",
    "            moveforward_for_resources_backfill_greedy(task_for_scheduling, scheduled_logs)\n",
    "\n",
    "        assert task_for_scheduling.scheduled_time == -1\n",
    "        task_for_scheduling.scheduled_time = current_timestamp\n",
    "        task_for_scheduling.allocated_machines = cluster.allocate(task_for_scheduling.task_id,\n",
    "                                                                      task_for_scheduling.request_number_of_processors)\n",
    "        running_tasks.append(task_for_scheduling)\n",
    "        score = (task_score(task_for_scheduling) / num_task_in_batch)\n",
    "        scheduled_logs[task_for_scheduling.task_id] = score\n",
    "        task_queue.remove(task_for_scheduling)\n",
    "\n",
    "        not_empty = moveforward_for_task()\n",
    "        if not not_empty:\n",
    "            break\n",
    "\n",
    "    cluster.reset()\n",
    "    loads.reset()\n",
    "    task_queue = []\n",
    "    running_tasks = []\n",
    "    vsbl_tasks = []\n",
    "    pairs = []\n",
    "    current_timestamp = loads[start].submit_time\n",
    "    task_queue.append(loads[start])\n",
    "    last_task_in_batch = start + num_task_in_batch\n",
    "    next_arriving_task_idx = start + 1\n",
    "\n",
    "    if enable_preworkloads:\n",
    "        refill_preworkloads()\n",
    "\n",
    "    return scheduled_logs\n",
    "\n",
    "def build_critic_obs():\n",
    "    vector = np.zeros(task_seq_siz * 3, dtype=float)\n",
    "    earlist_task = loads[start_idx_last_reset]\n",
    "    earlist_submit_time = earlist_task.submit_time\n",
    "    pairs = []\n",
    "    for i in range(start_idx_last_reset, last_task_in_batch + 1):\n",
    "        task = loads[i]\n",
    "        submit_time = task.submit_time - earlist_submit_time\n",
    "        request_processors = task.request_number_of_processors\n",
    "        request_time = task.request_time\n",
    "\n",
    "        normalized_submit_time = min(float(submit_time) / float(wait_max_t), 1.0 - 1e-5)\n",
    "        normalized_run_time = min(float(request_time) / float(loads.max_exec_time), 1.0 - 1e-5)\n",
    "        normalized_request_nodes = min(float(request_processors) / float(loads.max_procs), 1.0 - 1e-5)\n",
    "\n",
    "        pairs.append([normalized_submit_time, normalized_run_time, normalized_req_nodes])\n",
    "\n",
    "    for i in range(task_seq_siz):\n",
    "        vector[i * 3:(i + 1) * 3] = pairs[i]\n",
    "\n",
    "    return vector\n",
    "\n",
    "def build_observation():\n",
    "    vector = np.zeros((max_q_size) * task_fea, dtype=float)\n",
    "    task_queue.sort(key=lambda task: fcfs_score(task))\n",
    "    vsbl_tasks = []\n",
    "    for i in range(0, max_q_size):\n",
    "        if i < len(task_queue):\n",
    "            vsbl_tasks.append(task_queue[i])\n",
    "        else:\n",
    "            break\n",
    "    vsbl_tasks.sort(key=lambda j: fcfs_score(j))\n",
    "\n",
    "    vsbl_tasks = []\n",
    "    if len(task_queue) <= max_q_size:\n",
    "        for i in range(0, len(task_queue)):\n",
    "            vsbl_tasks.append(task_queue[i])\n",
    "    else:\n",
    "        vsbl_random = []\n",
    "        random_index = 0\n",
    "        shuffled = list(task_queue)\n",
    "        shuffle(shuffled)\n",
    "        for i in range(0, max_q_size):\n",
    "            vsbl_random.append(shuffled[i])\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        while index < max_q_size:\n",
    "\n",
    "            if (not random_task in vsbl_tasks) and index < max_q_size:\n",
    "                vsbl_tasks.append(random_task)\n",
    "                index += 1\n",
    "\n",
    "    pairs = []\n",
    "    add_skip = False\n",
    "    for i in range(0, max_q_size):\n",
    "        if i < len(vsbl_tasks) and i < (max_q_size):\n",
    "            task = vsbl_tasks[i]\n",
    "            submit_time = task.submit_time\n",
    "            req_processors = task.req_no_of_prccessors\n",
    "            req_time = task.request_time\n",
    "            wait_time = curr_timestamp - submit_time\n",
    "\n",
    "            nrml_wait_time = min(float(wait_time) / float(wait_max_t), 1.0 - 1e-5)\n",
    "            nrml_run_time = min(float(request_time) / float(loads.max_exec_time), 1.0 - 1e-5)\n",
    "            nrml_req_nodes = min(float(request_processors) / float(loads.max_procs), 1.0 - 1e-5)\n",
    "\n",
    "            if cluster.can_allocated(task):\n",
    "                can_schedule_now = 1.0 - 1e-5\n",
    "            else:\n",
    "                can_schedule_now = 1e-5\n",
    "            pairs.append(\n",
    "                [task, normalized_wait_time, normalized_run_time, normalized_request_nodes, can_schedule_now])\n",
    "        else:\n",
    "            pairs.append([None, 0, 1, 1, 0])\n",
    "\n",
    "    for i in range(0, max_q_size):\n",
    "        vector[i * task_fea:(i + 1) * task_fea] = pairs[i][1:]\n",
    "\n",
    "    return vector\n",
    "\n",
    "def moveforward_for_resources_backfill(task):\n",
    "    assert not cluster.can_allocated(task)\n",
    "    earliest_start_time = current_timestamp\n",
    "    running_tasks.sort(key=lambda running_task: (running_task.scheduled_time + running_task.request_time))\n",
    "    free_processors = cluster.free_node * cluster.num_procs_per_node\n",
    "    for running_task in running_tasks:\n",
    "        free_processors += len(running_task.allocated_machines) * cluster.num_procs_per_node\n",
    "        earliest_start_time = (running_task.scheduled_time + running_task.request_time)\n",
    "        if free_processors >= task.request_number_of_processors:\n",
    "            break\n",
    "\n",
    "    while not cluster.can_allocated(task):\n",
    "        task_queue.sort(key=lambda _j: fcfs_score(_j))\n",
    "        task_queue_iter_copy = list(task_queue)\n",
    "        for _j in task_queue_iter_copy:\n",
    "            if cluster.can_allocated(_j) and (current_timestamp + _j.request_time) < earliest_start_time:\n",
    "                assert _j.scheduled_time == -1\n",
    "                _j.scheduled_time = current_timestamp\n",
    "                _j.allocated_machines = cluster.allocate(_j.task_id, _j.request_number_of_processors)\n",
    "                running_tasks.append(_j)\n",
    "                score = (task_score(_j) / num_task_in_batch)\n",
    "                scheduled_rl[_j.task_id] = score\n",
    "                task_queue.remove(_j)\n",
    "        assert running_tasks\n",
    "        running_tasks.sort(key=lambda running_task: (running_task.scheduled_time + running_task.run_time))\n",
    "        next_resource_release_time = (running_tasks[0].scheduled_time + running_tasks[0].run_time)\n",
    "        next_resource_release_machines = running_tasks[0].allocated_machines\n",
    "\n",
    "        if next_arriving_task_idx < last_task_in_batch \\\n",
    "                and loads[next_arriving_task_idx].submit_time <= next_resource_release_time:\n",
    "            current_timestamp = max(current_timestamp, loads[next_arriving_task_idx].submit_time)\n",
    "            task_queue.append(loads[next_arriving_task_idx])\n",
    "            next_arriving_task_idx += 1\n",
    "        else:\n",
    "            current_timestamp = max(current_timestamp, next_resource_release_time)\n",
    "            cluster.release(next_resource_release_machines)\n",
    "            running_tasks.pop(0)\n",
    "\n",
    "def skip_for_resources():\n",
    "    assert running_tasks\n",
    "    running_tasks.sort(key=lambda running_task: (running_task.scheduled_time + running_task.run_time))\n",
    "    next_resource_release_time = (running_tasks[0].scheduled_time + running_tasks[0].run_time)\n",
    "    next_resource_release_machines = running_tasks[0].allocated_machines\n",
    "\n",
    "    if next_arriving_task_idx < last_task_in_batch and loads[\n",
    "        next_arriving_task_idx].submit_time <= next_resource_release_time:\n",
    "        current_timestamp = max(current_timestamp, loads[next_arriving_task_idx].submit_time)\n",
    "        task_queue.append(loads[next_arriving_task_idx])\n",
    "        next_arriving_task_idx += 1\n",
    "    else:\n",
    "        current_timestamp = max(current_timestamp, next_resource_release_time)\n",
    "        cluster.release(next_resource_release_machines)\n",
    "        running_tasks.pop(0)\n",
    "    return False\n",
    "\n",
    "def moveforward_for_task():\n",
    "    if task_queue:\n",
    "        return True\n",
    "    if next_arriving_task_idx >= last_task_in_batch:\n",
    "        assert not task_queue\n",
    "        return False\n",
    "    while not task_queue:\n",
    "        if not running_tasks:\n",
    "            next_resource_release_time = sys.maxsize\n",
    "            next_resource_release_machines = []\n",
    "        else:\n",
    "            running_tasks.sort(key=lambda running_task: (running_task.scheduled_time + running_task.run_time))\n",
    "            next_resource_release_time = (running_tasks[0].scheduled_time + running_tasks[0].run_time)\n",
    "            next_resource_release_machines = running_tasks[0].allocated_machines\n",
    "\n",
    "        if loads[next_arriving_task_idx].submit_time <= next_resource_release_time:\n",
    "            current_timestamp = max(current_timestamp, loads[next_arriving_task_idx].submit_time)\n",
    "            task_queue.append(loads[next_arriving_task_idx])\n",
    "            next_arriving_task_idx += 1\n",
    "            return True\n",
    "        else:\n",
    "            current_timestamp = max(current_timestamp, next_resource_release_time)\n",
    "            cluster.release(next_resource_release_machines)\n",
    "            running_tasks.pop(0)\n",
    "\n",
    "def task_score(task_for_scheduling):\n",
    "    reward = tf.random.normal(task_for_scheduling.run_time)\n",
    "    temp = (task_for_scheduling.scheduled_time - task_for_scheduling.submit_time + task_for_scheduling.run_time)/ max(task_for_scheduling.run_time, 10)\n",
    "    reward = reward * max(1.0,temp )\n",
    "    return reward\n",
    "\n",
    "def has_only_one_task():\n",
    "    if len(task_queue) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def skip_schedule(next_resource_release_time,running_tasks):\n",
    "    next_resource_release_time = sys.maxsize\n",
    "    next_resource_release_machines = []\n",
    "    if running_tasks:\n",
    "        running_tasks.sort(key=lambda running_task: (running_task.scheduled_time + running_task.run_time))\n",
    "        next_resource_release_time = (running_tasks[0].scheduled_time + running_tasks[0].run_time)\n",
    "        next_resource_release_machines = running_tasks[0].allocated_machines\n",
    "\n",
    "    if next_arriving_task_idx >= last_task_in_batch and not running_tasks:\n",
    "        if not pivot_task:\n",
    "            pivot_task = True\n",
    "            return False, 0\n",
    "        else:\n",
    "            return False, 0\n",
    "\n",
    "    if next_arriving_task_idx < last_task_in_batch and loads[\n",
    "        next_arriving_task_idx].submit_time <= next_resource_release_time:\n",
    "        current_timestamp = max(current_timestamp, loads[next_arriving_task_idx].submit_time)\n",
    "        task_queue.append(loads[next_arriving_task_idx])\n",
    "        next_arriving_task_idx += 1\n",
    "    else:\n",
    "        current_timestamp = max(current_timestamp, next_resource_release_time)\n",
    "        cluster.release(next_resource_release_machines)\n",
    "        running_tasks.pop(0)\n",
    "    return False, 0\n",
    "\n",
    "def schedule(task_for_scheduling):\n",
    "    if not cluster.can_allocated(task_for_scheduling):\n",
    "        moveforward_for_resources_backfill(task_for_scheduling)\n",
    "\n",
    "    assert task_for_scheduling.scheduled_time == -1\n",
    "    task_for_scheduling.scheduled_time = current_timestamp\n",
    "    task_for_scheduling.allocated_machines = cluster.allocate(task_for_scheduling.task_id,\n",
    "                                                                  task_for_scheduling.request_number_of_processors)\n",
    "    running_tasks.append(task_for_scheduling)\n",
    "    score = (task_score(task_for_scheduling) / num_task_in_batch)\n",
    "    scheduled_rl[task_for_scheduling.task_id] = score\n",
    "    task_queue.remove(task_for_scheduling)\n",
    "\n",
    "    not_empty = moveforward_for_task()\n",
    "\n",
    "    if not_empty:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def valid(a):\n",
    "    action = a[0]\n",
    "    return pairs[action][0]\n",
    "\n",
    "def step(a):\n",
    "    task_for_scheduling = pairs[a][0]\n",
    "\n",
    "    if not task_for_scheduling:\n",
    "        done, _ = skip_schedule()\n",
    "    else:\n",
    "        task_for_scheduling = pairs[a][0]\n",
    "        done = schedule(task_for_scheduling)\n",
    "\n",
    "    if not done:\n",
    "        obs = build_observation()\n",
    "        return [obs, 0, False, 0]\n",
    "    else:\n",
    "        rl_total = sum(scheduled_rl.values())\n",
    "        rwd = -rl_total\n",
    "        return [None, rwd, True]\n",
    "\n",
    "def step_for_test(a):\n",
    "    task_for_scheduling = pairs[a][0]\n",
    "\n",
    "    if not task_for_scheduling:\n",
    "        done, _ = skip_schedule()\n",
    "    else:\n",
    "        task_for_scheduling = pairs[a][0]\n",
    "        done = schedule(task_for_scheduling)\n",
    "\n",
    "    if not done:\n",
    "        obs = build_observation()\n",
    "        return [obs, 0, False, None]\n",
    "    else:\n",
    "        rl_total = sum(scheduled_rl.values())\n",
    "        return [None, rl_total, True, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c33fff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "HPC_env = HPC_Environment()\n",
    "\n",
    "ddpg.train(gym_env, True, max_episodes=1000)\n",
    "ddpg.test(max_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9595544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading Workloads\n",
    "tasks_all = []\n",
    "\n",
    "def workload_start(path):\n",
    "    max_val = 0\n",
    "    max_exec_time = 0\n",
    "    min_exec_time = sys.maxsize\n",
    "    max_task_id = 0\n",
    "    max_group_id = 0\n",
    "    max_executable_number = 0\n",
    "    max_task_id = 0\n",
    "    max_nodes = 0\n",
    "    max_procs = 0\n",
    "\n",
    "    with open(path) as oline:\n",
    "        for line in oline:\n",
    "            if line.startswith(\";\"):\n",
    "                if line.startswith(\"; MaxNodes:\"):\n",
    "                    max_nodes = int(line.split(\":\")[1].strip())\n",
    "                if line.startswith(\"; MaxProcs:\"):\n",
    "                    max_procs = int(line.split(\":\")[1].strip())\n",
    "                continue\n",
    "\n",
    "            o = start_task(line)\n",
    "            if o.run_time >max_exec_time:\n",
    "                max_exec_time = o.run_time\n",
    "            if o.run_time < min_exec_time:\n",
    "                min_exec_time = o.run_time\n",
    "\n",
    "            all_tasks.append(o)\n",
    "\n",
    "            if o.request_number_of_processors > max_val:\n",
    "                max = t.request_number_of_processors\n",
    "\n",
    "    if max_procs == 0:\n",
    "        max_procs = max_nodes\n",
    "\n",
    "    all_tasks.sort(key=lambda task: task.task_id)\n",
    "\n",
    "def size(all_tasks):\n",
    "    return len(all_tasks)\n",
    "\n",
    "def reset_load(all_tasks):\n",
    "    for task in all_tasks:\n",
    "        task.scheduled_time = -1\n",
    "\n",
    "def obtain_work_item(all_tasks, item):\n",
    "    return all_tasks[item]\n",
    "\n",
    "oload = workload_start('ANL-Intrepid-2009-1.swf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8d4bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Load Tasks\n",
    "def start_task(line=\"0        0      0    0   0     0    0   0  0 0  0   0   0  0  0 0 0 0\"):\n",
    "    line = line.strip()\n",
    "    s_array = re.split(\"\\\\s+\", line)\n",
    "    task_id = int(s_array[0])\n",
    "    submit_time = int(s_array[1])\n",
    "    wait_time = int(s_array[2])\n",
    "    run_time = int(s_array[3])\n",
    "    no_of_alloc_proce = int(s_array[4])\n",
    "    avg_cpu_time_used = float(s_array[5])\n",
    "    used_memory = int(s_array[6])\n",
    "\n",
    "    req_no_of_proc = int(s_array[7])\n",
    "    no_of_alloc_proce = max(no_of_alloc_proce,req_no_of_proc)\n",
    "    req_no_of_proc = no_of_alloc_proce\n",
    "\n",
    "    req_no_of_proc = -1\n",
    "\n",
    "    request_time = int(s_array[8])\n",
    "    if request_time == -1:\n",
    "        request_time = run_time\n",
    "\n",
    "    req_mem = int(s_array[9])\n",
    "    status = int(s_array[10])\n",
    "    user_id = int(s_array[11])\n",
    "    group_id = int(s_array[12])\n",
    "    exe_no = int(s_array[13])\n",
    "    q_no = int(s_array[14])\n",
    "\n",
    "    try:\n",
    "        part_no = int(s_array[15])\n",
    "    except ValueError:\n",
    "        part_no = 0\n",
    "\n",
    "    proceeding_task_number = int(s_array[16])\n",
    "    othink_time_from_proceeding_task = int(s_array[17])\n",
    "\n",
    "    random_id = .submit_time\n",
    "\n",
    "    scheduled_time = -1\n",
    "\n",
    "    alloc_mac = None\n",
    "\n",
    "    slurm_in_queue_time = 0\n",
    "    slurm_age = 0\n",
    "    slurm_task_size = 0.0\n",
    "    slurm_fair = 0.0\n",
    "    slurm_partition = 0\n",
    "    slurm_qos = 0\n",
    "    slurm_tres_cpu = 0.0\n",
    "\n",
    "def task_q(other,task_id):\n",
    "    return task_id == other.task_id\n",
    "\n",
    "def task_str(task_id,submit_time,req_time,req_no_of_proc):\n",
    "    return \"t[\" + str(task_id) + \"]-[\" + str(req_no_of_proc) + \"]-[\" + str(submit_time) + \"]-[\" + str(req_time) + \"]\"\n",
    "\n",
    "def task_feat(submit_time,req_no_of_proc,req_time,user_id,group_id, exe_no,q_no):\n",
    "    return [submit_time, req_no_of_proc, req_time,user_id, group_id, exe_no, q_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2fdfc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#DDPG\n",
    "def actor(state_shape, action_dim, action_bound, action_shift, units=(400, 300)):\n",
    "    state = Input(shape=state_shape)\n",
    "    x = Dense(units[0], name=\"L0\", activation='relu')(state)\n",
    "    for index in range(1, len(units)):\n",
    "        x = Dense(units[index], name=\"L{}\".format(index), activation='relu')(x)\n",
    "\n",
    "    unscaled_output = Dense(action_dim, name=\"Out\", activation='tanh')(x)\n",
    "    scalar = action_bound * np.ones(action_dim)\n",
    "    output = Lambda(lambda op: op * scalar)(unscaled_output)\n",
    "    if np.sum(action_shift) != 0:\n",
    "        output = Lambda(lambda op: op + action_shift)(output)  # for action range not centered at zero\n",
    "\n",
    "    model = Model(inputs=state, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def critic(state_shape, action_dim, units=(48, 24)):\n",
    "    inputs = [Input(shape=state_shape), Input(shape=(action_dim,))]\n",
    "    concat = Concatenate(axis=-1)(inputs)\n",
    "    x = Dense(units[0], name=\"L0\", activation='relu')(concat)\n",
    "    for index in range(1, len(units)):\n",
    "        x = Dense(units[index], name=\"L{}\".format(index), activation='relu')(x)\n",
    "    output = Dense(1, name=\"Out\")(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "def update_target_weights(model, target_model, tau=0.005):\n",
    "    weights = model.get_weights()\n",
    "    target_weights = target_model.get_weights()\n",
    "    for i in range(len(target_weights)):  # set tau% of target model to be new weights\n",
    "        target_weights[i] = weights[i] * tau + target_weights[i] * (1 - tau)\n",
    "    target_model.set_weights(target_weights)\n",
    "\n",
    "\n",
    "def ddpg_start(env,False,False,lr_act=0.001,lr_cric=0.01,actor_units=(24, 16),critic_units=(24, 16),sig=0.15,tu=0.125,gam=0.85,\n",
    "               batch_size=32,memory_cap=10000)\n",
    "\n",
    "    state_shape = observation_space.shape  # shape of observations\n",
    "    action_dim = action_space.n\n",
    "    discrete = discrete\n",
    "    action_bound = (env.action_space.high - env.action_space.low) / 2 if not discrete else 1.\n",
    "    action_shift = (env.action_space.high + env.action_space.low) / 2 if not discrete else 0.\n",
    "    use_priority = use_priority\n",
    "    memory = Memory_start(capacity=memory_cap) if use_priority else deque(maxlen=memory_cap)\n",
    "    if noise == 'ou':\n",
    "        noise = OrnsteinUhlenbeckNoise(mu=np.zeros(.action_dim), sigma=sigma)\n",
    "    else:\n",
    "        noise = NormalNoise(mu=np.zeros(.action_dim), sigma=sigma)\n",
    "\n",
    "    # Define and initialize Actor network\n",
    "    actor = actor(.state_shape, .action_dim, .action_bound, .action_shift, actor_units)\n",
    "    actor_target = actor(.state_shape, .action_dim, .action_bound, .action_shift, actor_units)\n",
    "    actor_optimizer = Adam(learning_rate=lr_actor)\n",
    "    update_target_weights(.actor, .actor_target, tau=1.)\n",
    "\n",
    "    # Define and initialize Critic network\n",
    "    critic = critic(.state_shape, .action_dim, critic_units)\n",
    "    critic_target = critic(.state_shape, .action_dim, critic_units)\n",
    "    critic_optimizer = Adam(learning_rate=lr_critic)\n",
    "    update_target_weights(.critic, .critic_target, tau=1.)\n",
    "\n",
    "    # Set hyperparameters\n",
    "    gamma = gamma  # discount factor\n",
    "    tau = tau  # target model update\n",
    "    batch_size = batch_size\n",
    "\n",
    "    # Tensorboard\n",
    "    summaries = {}\n",
    "\n",
    "def act(state, add_noise=True):\n",
    "    state = np.expand_dims(state, axis=0).astype(np.float32)\n",
    "    a = actor.predict(state)\n",
    "    a += noise() * add_noise * action_bound\n",
    "    a = tf.clip_by_value(a, -action_bound + action_shift, action_bound + action_shift)\n",
    "\n",
    "    summaries['q_val'] =critic.predict([state, a])[0][0]\n",
    "\n",
    "    return a\n",
    "\n",
    "def save_model(a_fn, c_fn):\n",
    "    actor.save(a_fn)\n",
    "    critic.save(c_fn)\n",
    "\n",
    "def load_actor(, a_fn):\n",
    "    actor.load_weights(a_fn)\n",
    "    actor_target.load_weights(a_fn)\n",
    "    print(actor.summary())\n",
    "\n",
    "def load_critic(, c_fn):\n",
    "    critic.load_weights(c_fn)\n",
    "    critic_target.load_weights(c_fn)\n",
    "    print(critic.summary())\n",
    "\n",
    "def remember(state, action, reward, next_state, done):\n",
    "    if use_priority:\n",
    "        action = np.squeeze(action)\n",
    "        transition = np.hstack([state, action, reward, next_state, done])\n",
    "        memory.store(transition)\n",
    "    else:\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        next_state = np.expand_dims(next_state, axis=0)\n",
    "        memory.append([state, action, reward, next_state, done])\n",
    "\n",
    "def replay():\n",
    "\n",
    "    if use_priority:\n",
    "        tree_idx, samples, ISWeights = memory.sample(.batch_size)\n",
    "        split_shape = np.cumsum([state_shape[0], action_dim, 1, state_shape[0]])\n",
    "        states, actions, rewards, next_states, dones = np.hsplit(samples, split_shape)\n",
    "    else:\n",
    "        ISWeights = 1.0\n",
    "        samples = random.sample(memory, batch_size)\n",
    "        s = np.array(samples).T\n",
    "        states, actions, rewards, next_states, dones = [np.vstack(s[i, :]).astype(np.float) for i in range(5)]\n",
    "\n",
    "    next_actions = actor_target.predict(next_states)\n",
    "    q_future = critic_target.predict([next_states, next_actions])\n",
    "    target_qs = rewards + q_future * gamma * (1. - dones)\n",
    "\n",
    "    # train critic\n",
    "    with tf.GradientTape() as tape:\n",
    "        q_values = critic([states, actions])\n",
    "        td_error = q_values - target_qs\n",
    "        critic_loss = tf.reduce_mean(ISWeights * tf.math.square(td_error))\n",
    "\n",
    "    critic_grad = tape.gradient(critic_loss, .critic.trainable_variables)  # compute critic gradient\n",
    "    critic_optimizer.apply_gradients(zip(critic_grad, .critic.trainable_variables))\n",
    "\n",
    "    # update priority\n",
    "    if use_priority:\n",
    "        abs_errors = tf.reduce_sum(tf.abs(td_error), axis=1)\n",
    "        memory.batch_update(tree_idx, abs_errors)\n",
    "\n",
    "    # train actor\n",
    "    with tf.GradientTape() as tape:\n",
    "        actions = actor(states)\n",
    "        actor_loss = -tf.reduce_mean(.critic([states, actions]))\n",
    "\n",
    "    actor_grad = tape.gradient(actor_loss, .actor.trainable_variables)  # compute actor gradient\n",
    "    actor_optimizer.apply_gradients(zip(actor_grad, .actor.trainable_variables))\n",
    "\n",
    "    # tensorboard info\n",
    "    summaries['critic_loss'] = critic_loss\n",
    "    summaries['actor_loss'] = actor_loss\n",
    "\n",
    "def train(max_episodes=50, max_epochs=8000, max_steps=500, save_freq=50):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    train_log_dir = 'logs/DDPG_basic_' + current_time\n",
    "    summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "    done, episode, steps, epoch, total_reward = False, 0, 0, 0, 0\n",
    "    cur_state = env.reset()\n",
    "    while episode < max_episodes or epoch < max_epochs:\n",
    "        if done:\n",
    "            episode += 1\n",
    "            print(\"episode {}: {} total reward, {} steps, {} epochs\".format(episode, total_reward, steps, epoch))\n",
    "\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('Main/episode_reward', total_reward, step=episode)\n",
    "                tf.summary.scalar('Main/episode_steps', steps, step=episode)\n",
    "\n",
    "            summary_writer.flush()\n",
    "            noise.reset()\n",
    "\n",
    "            if steps >= max_steps:\n",
    "                print(\"episode {}, reached max steps\".format(episode))\n",
    "                save_model(\"ddpg_actor_episode{}.p\".format(episode),\n",
    "                                \"ddpg_critic_episode{}.p\".format(episode))\n",
    "\n",
    "            done, cur_state, steps, total_reward = False, .env.reset(), 0, 0\n",
    "            if episode % save_freq == 0:\n",
    "                save_model(\"ddpg_actor_episode{}.p\".format(episode),\n",
    "                                \"ddpg_critic_episode{}.p\".format(episode))\n",
    "\n",
    "        a = act(cur_state)  # model determine action given state\n",
    "        action = np.argmax(a) if .discrete else a[0]  # post process for discrete action space\n",
    "        next_state, reward, done, _ = .env.step(action)  # perform action on env\n",
    "\n",
    "        remember(cur_state, a, reward, next_state, done)  # add to memory\n",
    "        replay()  # train models through memory replay\n",
    "\n",
    "        update_target_weights(actor, actor_target, tu)  # iterates target model\n",
    "        update_target_weights(critic, critic_target, tu)\n",
    "\n",
    "        cur_state = next_state\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        epoch += 1\n",
    "\n",
    "        # Tensorboard update\n",
    "        with summary_writer.as_default():\n",
    "            if len(.memory) > batch_size:\n",
    "                tf.summary.scalar('Loss/actor_loss', summaries['actor_loss'], step=epoch)\n",
    "                tf.summary.scalar('Loss/critic_loss', summaries['critic_loss'], step=epoch)\n",
    "            tf.summary.scalar('Main/step_reward', reward, step=epoch)\n",
    "            tf.summary.scalar('Stats/q_val', .summaries['q_val'], step=epoch)\n",
    "\n",
    "        summary_writer.flush()\n",
    "\n",
    "    save_model(\"ddpg_actor_final_episode{}.p\".format(episode),\n",
    "                    \"ddpg_critic_final_episode{}.p\".format(episode))\n",
    "\n",
    "def test(epi):\n",
    "    cur_state, done, rewards = env.reset(), False, 0\n",
    "    while not done:\n",
    "        a = act(cur_state, add_noise=False)\n",
    "        action = np.argmax(a) if discrete else a[0]  # post process for discrete action space\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        cur_state = next_state\n",
    "        rewards += reward\n",
    "        if render:\n",
    "            video.append_data(env.render(mode='rgb_array'))\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e0cfbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "HPC_env = HPC_Environment()\n",
    "\n",
    "ddpg.train(gym_env, True, max_episodes=500)\n",
    "ddpg.test(max_episodes=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a16d62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.01 \n",
    "alpha = 0.7 \n",
    "beta = 0.5\n",
    "beta_increment_per_sampling = 0.001\n",
    "abs_err_upper = 1\n",
    "\n",
    "def memory_init(capacity):\n",
    "    tree = SumTree(capacity)\n",
    "    sample_count = 0\n",
    "\n",
    "def __len__(self):\n",
    "    return sample_count\n",
    "\n",
    "def store( transition):\n",
    "    max_p = np.max(tree.tree[-tree.capacity:])\n",
    "    if max_p == 0:\n",
    "        max_p = abs_err_upper\n",
    "    tree.add(max_p, transition) \n",
    "    sample_count = min(sample_count + 1, tree.capacity)\n",
    "\n",
    "def sample(n):\n",
    "    b_idx, b_memory, ISWeights = np.empty((n,), dtype=np.int32), np.empty((n, tree.data[0].size)), np.empty((n, 1))\n",
    "    pri_seg = tree.total_p / n\n",
    "    beta = np.min([1., beta + beta_increment_per_sampling])\n",
    "\n",
    "    a = tree.tree[-tree.capacity:]\n",
    "    min_prob = np.min(a[a != 0]) / tree.total_p  \n",
    "    for i in range(n):\n",
    "        a, b = pri_seg * i, pri_seg * (i + 1)\n",
    "        v = np.random.uniform(a, b)\n",
    "        idx, p, data = tree.get_leaf(v)\n",
    "        prob = p / tree.total_p\n",
    "        ISWeights[i, 0] = np.power(prob/min_prob, -beta)\n",
    "        b_idx[i], b_memory[i, :] = idx, data\n",
    "\n",
    "    return b_idx, b_memory, ISWeights\n",
    "\n",
    "def batch_update( tree_idx, abs_errors):\n",
    "    abs_errors += epsilon  # convert to abs and avoid 0\n",
    "    clipped_errors = np.minimum(abs_errors, abs_err_upper)\n",
    "    ps = np.power(clipped_errors, alpha)\n",
    "    for ti, p in zip(tree_idx, ps):\n",
    "        tree.update(ti, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecab659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_pointer = 0\n",
    "\n",
    "def strt_SumTree(capacity):\n",
    "    tree = np.zeros(2 * capacity - 1)\n",
    "    data = np.zeros(capacity, dtype=object)\n",
    "    return tree,data\n",
    "    \n",
    "def add(p, data, data_pointer):\n",
    "    tree_idx = data_pointer + capacity - 1\n",
    "    data[data_pointer] = data \n",
    "    update(tree_idx, p) \n",
    "    data_pointer += 1\n",
    "    if data_pointer >= capacity: \n",
    "        data_pointer = 0\n",
    "\n",
    "def update(tree_idx, p):\n",
    "    change = p - tree[tree_idx]\n",
    "    tree[tree_idx] = p\n",
    "    while tree_idx != 0:   \n",
    "        tree_idx = (tree_idx - 1) // 2\n",
    "        tree[tree_idx] += change\n",
    "\n",
    "def get_leaf(v):\n",
    "    parent_idx = 0\n",
    "    while True:  \n",
    "        cl_idx = 2 * parent_idx + 1      \n",
    "        cr_idx = cl_idx + 1\n",
    "        if cl_idx >= len(tree):     \n",
    "            leaf_idx = parent_idx\n",
    "            break\n",
    "        else:     \n",
    "            if v <= tree[cl_idx]:\n",
    "                parent_idx = cl_idx\n",
    "            else:\n",
    "                v -= tree[cl_idx]\n",
    "                parent_idx = cr_idx\n",
    "\n",
    "    data_idx = leaf_idx - capacity + 1\n",
    "    return leaf_idx, tree[leaf_idx], data[data_idx]\n",
    "\n",
    "def total_p(tree):\n",
    "    return tree[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
